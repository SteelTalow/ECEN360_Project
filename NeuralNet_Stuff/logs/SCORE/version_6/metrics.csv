epoch,step,train_loss,valid_loss
0,19,,220.0485382080078
0,19,339.4517517089844,
1,39,,227.3579559326172
1,39,213.7708740234375,
2,59,,199.30194091796875
2,59,190.45921325683594,
3,79,,177.4251251220703
3,79,186.53334045410156,
4,99,,171.60012817382812
4,99,171.83836364746094,
5,119,,177.28524780273438
5,119,173.5395050048828,
6,139,,182.60165405273438
6,139,184.52398681640625,
7,159,,177.92770385742188
7,159,171.31747436523438,
8,179,,187.57937622070312
8,179,180.31224060058594,
9,199,,190.99024963378906
9,199,166.6592559814453,
10,219,,199.4857177734375
10,219,173.12229919433594,
11,239,,171.99867248535156
11,239,154.00106811523438,
12,259,,200.21751403808594
12,259,184.24325561523438,
13,279,,178.65243530273438
13,279,161.06399536132812,
14,299,,171.71669006347656
14,299,176.53289794921875,
15,319,,181.40963745117188
15,319,154.20205688476562,
16,339,,166.7180938720703
16,339,172.93101501464844,
17,359,,188.7369842529297
17,359,172.44168090820312,
18,379,,197.25515747070312
18,379,158.21881103515625,
19,399,,188.28646850585938
19,399,167.9231414794922,
20,419,,174.1089324951172
20,419,174.20372009277344,
21,439,,193.25596618652344
21,439,172.20571899414062,
22,459,,161.53990173339844
22,459,164.87265014648438,
23,479,,165.47781372070312
23,479,168.76400756835938,
24,499,,161.1103057861328
24,499,167.10781860351562,
25,519,,158.72500610351562
25,519,160.5813446044922,
26,539,,167.961669921875
26,539,155.42750549316406,
27,559,,158.58377075195312
27,559,152.38194274902344,
28,579,,160.3729248046875
28,579,159.97732543945312,
29,599,,177.671875
29,599,176.67919921875,
